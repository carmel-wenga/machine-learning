{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Recognition with MLP and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents a simple guideline on how to implement a handwritten digit recognition with a simple neural networks called Multilayer Perceptron. In this guideline, I will use the ```tensorflow.keras``` high-level API to build the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Tensorflow 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Visualize MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data is incorporated in the ```keras``` library. It contains $70.000$ grayscale images of handwritten digits separated into a training set of $60.000$ examples and a test set of $10.000$ examples. We can simply load the data by running the following cell.\n",
    "\n",
    "1. ```(x_train, y_train)``` : is the training set.\n",
    "2. ```(x_test, y_test)``` : is the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each training example is a $28\\times28$ pixels image associated with a label corresponding to its value. Run the cell below to randomly visualize 10 examples of handwritten digits with their corresponding labels. Run this cell multiple times to see another examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# select 10 random images from the first 100 examples\n",
    "rand_examples = np.random.randint(100, size=10)\n",
    "\n",
    "# defining the grid\n",
    "cols = 5\n",
    "rows = 2\n",
    "\n",
    "# size of images in the grid\n",
    "fig = plt.figure(figsize = (10,4))\n",
    "\n",
    "axis = []\n",
    "\n",
    "for i, expl in enumerate(rand_examples) :\n",
    "    # get the img and its corresponding label\n",
    "    img = x_train[expl,:,:]\n",
    "    label = y_train[expl]\n",
    "    \n",
    "    # add subplot to the grid\n",
    "    axis.append(fig.add_subplot(rows,cols,i+1))\n",
    "    \n",
    "    # display current image in the grid\n",
    "    axis[i].imshow(img)\n",
    "    axis[i].set_title(\"y = {}\".format(label))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 training examples of shape  (28, 28)\n",
      "60000 labels for training examples\n",
      "10000 test examples of shape  (28, 28)\n",
      "10000 labels for test examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape[0], 'training examples of shape ',x_train.shape[1:])\n",
    "print(y_train.shape[0], 'labels for training examples')\n",
    "print(x_test.shape[0], 'test examples of shape ',x_test.shape[1:])\n",
    "print(y_test.shape[0], 'labels for test examples')\n",
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and Normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel intensities of MNIST data are represented as integers (from 0 to 255) rather than floats (from 0.0 to 255.0). Since we will gradient descent to train our classifier, we need these values to be floats instead of intergers. Moreover, in order to efficiently train the model using gradient descent, we will scale the pixel intensities down to the 0-1 range by dividing them by 255.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model defined here is a 4 layers MLP :\n",
    "\n",
    "1. Inuput layer. The input layer is a flatten vector of the input image. Pixel values are enrolled into a long vector of shape $(784,)$. This is the ```Flatten``` layer\n",
    "2. Hidden 1 : 300 units\n",
    "3. Hidden 2 : 100 units\n",
    "4. Output layer : 10 units. It contains as many output as there are output classes (10 output classes from 0 to 9). Each unit in the output layer outputs the probability that the input image belongs to the corresponding class.\n",
    "\n",
    "The figure below present the summary of our model\n",
    "\n",
    "<img src=\"img/mnist-model.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    # input layer : enroll the input image into a long vector of shape (784,)\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    \n",
    "    # hidden 1\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    \n",
    "    # hidden 2\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    \n",
    "    # output layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. loss : ```sparse_categorical_crossentropy``` is used for integer labels $y\\in\\{0,...,9\\}$. If labels were one hot representations of these values, we would have used ```categorical_crossentropy```.\n",
    "2. optimizer : ```SGD```.\n",
    "3. metrics : ```['accuracy']```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.SGD(lr=0.00001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important hyperparameter to tune when training machine learning model is the learning rate ```lr```. The performance of the model largely depends on the value of the learning rate.\n",
    "\n",
    "### How to choose the appropriate learning rate for a model ?\n",
    "\n",
    "1. Initialize the learning rate with a very low value, say $10^{-5}$\n",
    "2. Train the model for a few hundred iterations\n",
    "3. After each iteration, increase the learning rate by by multiplying it by a constant factor, say $\\exp(\\log(10^6 )/500)$\n",
    "4. After training, plot the loss as a function of the learning rate.\n",
    "5. The optimal learning will be a bit lower than the point that minimize the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize the learning rate to be $10^{-5}$ with ```SGD(lr=0.00001)```\n",
    "- By training the model with ```batch_size=2```, the training process will iterate 30k times to process the entire training set.\n",
    "- After each iteration, multiply the learning by a ```factor=1.0004```. You can change this value to experiment it yourself. Class ```LearningRateSchedule``` is called while training and after each batch iteration, function ```on_batch_end()``` increase the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class LearningRateSchedule(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.lrates = []\n",
    "        self.losses = []\n",
    "    \n",
    "    def on_batch_end(self, epoch, logs):\n",
    "        # keep track of the current learning rate and loss\n",
    "        self.lrates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        \n",
    "        # increase the learning rate, by multiplying it by the factor\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "\n",
    "factor=1.0004\n",
    "lr_scheduler = LearningRateSchedule(factor=factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's fit the model with one epochs to find the appropriate learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2/30000 [..............................] - ETA: 54:03 - loss: 2.6072 - accuracy: 0.0000e+00WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.107664). Check your callbacks.\n",
      " 4909/30000 [===>..........................] - ETA: 1:08 - loss: 2.3154 - accuracy: 0.1033"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=1,\n",
    "    batch_size=2,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the lost as a function of the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lr_scheduler.lrates, lr_scheduler.losses)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.hlines(min(lr_scheduler.losses), min(lr_scheduler.lrates), max(lr_scheduler.lrates))\n",
    "plt.axis([min(lr_scheduler.lrates), max(lr_scheduler.lrates), 0, lr_scheduler.losses[0]])\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss goes down and starts shooting back up violently around 1e-1. Let's sort the losses according to the learning rate to know exactly which value to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_lr = zip(lr_scheduler.losses, lr_scheduler.lrates)\n",
    "loss_lr = sorted(loss_lr)\n",
    "best_lr = loss_lr[0][1]\n",
    "print(\"min_loss = \", loss_lr[0][0])\n",
    "print(\"corresponding lr = \", loss_lr[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$lr=0.1400017$ is then the learning rate that minimizes the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lr = best_lr - 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    # input layer : enroll the input image into a long vector of shape (784,)\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    \n",
    "    # hidden 1\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    \n",
    "    # hidden 2\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    \n",
    "    # output layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recompile the model\n",
    "print('learning rate lr = ', new_lr)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.SGD(lr=new_lr),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(keras.callbacks.Callback):    \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if logs.get('accuracy')>0.98:\n",
    "            print('\\nReaching 98% of accurary, then stopping training')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# saving checkpoint of the model\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('mnist_model.h5', save_best_only=True)\n",
    "\n",
    "# stop training if it reaches 98% of accuracy\n",
    "early_stopping = EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks = [checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on a few test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = x_test[:3]\n",
    "model.predict(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author\n",
    "\n",
    "Carmel WENGA | Applied Machine Learning Research Engineer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_v2",
   "language": "python",
   "name": "tensorflow_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
